<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.23" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.152" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"模型训练的梳理","image":[""],"dateModified":"2025-07-12T11:41:17.000Z","author":[]}</script><meta property="og:url" content="https://try-catch.life/article/kw8yy12a/"><meta property="og:site_name" content="码不停蹄"><meta property="og:title" content="模型训练的梳理"><meta property="og:description" content="一、模型训练的完整过程 机器学习模型的训练通常遵循固定流程，每个环节的质量都会直接影响最终模型的性能。 以下是训练的核心步骤： 1. 数据准备与预处理 数据收集：获取与任务相关的原始数据（如文本、图像、数值等），需保证数据的相关性和代表性。 数据清洗：处理缺失值（填充、删除）、异常值（修正、剔除）、重复值（去重），避免噪声影响模型。 特征工程： 特征选..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-07-12T11:41:17.000Z"><meta property="article:tag" content="AI"><meta property="article:tag" content="模型训练"><meta property="article:tag" content="机器学习"><meta property="article:modified_time" content="2025-07-12T11:41:17.000Z"><link rel="icon" type="image/png" href="/logo.svg"><title>模型训练的梳理 | 码不停蹄</title><meta name="description" content="一、模型训练的完整过程 机器学习模型的训练通常遵循固定流程，每个环节的质量都会直接影响最终模型的性能。 以下是训练的核心步骤： 1. 数据准备与预处理 数据收集：获取与任务相关的原始数据（如文本、图像、数值等），需保证数据的相关性和代表性。 数据清洗：处理缺失值（填充、删除）、异常值（修正、剔除）、重复值（去重），避免噪声影响模型。 特征工程： 特征选..."><link rel="preload" href="/assets/style-D0q-vulE.css" as="style"><link rel="stylesheet" href="/assets/style-D0q-vulE.css"><link rel="modulepreload" href="/assets/app-CYGu30PL.js"><link rel="modulepreload" href="/assets/index.html-kWjr082p.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-1817aa03><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-a22fbb18></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-a22fbb18> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-1817aa03 data-v-f1574a4f><div class="vp-navbar" vp-navbar data-v-f1574a4f data-v-1ccbf436><div class="wrapper" data-v-1ccbf436><div class="container" data-v-1ccbf436><div class="title" data-v-1ccbf436><div class="vp-navbar-title" data-v-1ccbf436 data-v-e48140ae><a class="vp-link no-icon link title" href="/" data-v-e48140ae data-v-3ce037c9><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/logo.svg" alt data-v-75e8092e><!--]--><!--[--><img class="vp-image light logo" style="" src="/logo.svg" alt data-v-75e8092e><!--]--><!--]--><!--]--><span data-v-e48140ae>码不停蹄</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-1ccbf436><div class="content-body" data-v-1ccbf436><!--[--><!--]--><div class="vp-navbar-search search" data-v-1ccbf436><div class="search-wrapper" data-v-bb5a6f9d><!----><div id="local-search" data-v-bb5a6f9d><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-bb5a6f9d><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-1ccbf436 data-v-3678d5a9><span id="main-nav-aria-label" class="visually-hidden" data-v-3678d5a9>Main Navigation</span><!--[--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/blog/" tabindex="0" data-v-3678d5a9 data-v-a950b8e7 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-a950b8e7 data-v-72b81a46><img src="/icons/blog.svg" alt="" style="" data-v-72b81a46></span><span data-v-a950b8e7>博客</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/blog/tags/" tabindex="0" data-v-3678d5a9 data-v-a950b8e7 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-a950b8e7 data-v-72b81a46><img src="/icons/blog.svg" alt="" style="" data-v-72b81a46></span><span data-v-a950b8e7>标签</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/blog/categories/" tabindex="0" data-v-3678d5a9 data-v-a950b8e7 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-a950b8e7 data-v-72b81a46><img src="/icons/blog.svg" alt="" style="" data-v-72b81a46></span><span data-v-a950b8e7>分类</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/blog/archives/" tabindex="0" data-v-3678d5a9 data-v-a950b8e7 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-a950b8e7 data-v-72b81a46><img src="/icons/blog.svg" alt="" style="" data-v-72b81a46></span><span data-v-a950b8e7>归档</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-3678d5a9 data-v-9b8751cb><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9b8751cb><span class="text" data-v-9b8751cb><span class="vp-icon-img" aria-hidden data-v-9b8751cb data-v-72b81a46><img src="/icons/blog.svg" alt="" style="" data-v-72b81a46></span><!----><span data-v-9b8751cb>工具</span><!----><span class="vpi-chevron-down text-icon" data-v-9b8751cb></span></span></button><div class="menu" data-v-9b8751cb><div class="vp-menu" data-v-9b8751cb data-v-0d2be8ee><div class="items" data-v-0d2be8ee><!--[--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://try-catch.life/colorful-board/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/color-board.svg" alt="" style="" data-v-72b81a46></span> mini调色板 <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://try-catch.life/emoji-display/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/emoji_loveface.svg" alt="" style="" data-v-72b81a46></span> emoji大全 <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://try-catch.life/echarts-demo/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/chart-logo.svg" alt="" style="" data-v-72b81a46></span> Echarts学习 <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://try-catch.life/img-tools/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/img-tools-logo.svg" alt="" style="" data-v-72b81a46></span> 图片处理工具 <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://marklite.surge.sh/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/markdown-editor-logo.svg" alt="" style="" data-v-72b81a46></span> 素笔 Mark 编辑器 <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://try-catch.life/pdf-to-picture/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/pdf-logo.svg" alt="" style="" data-v-72b81a46></span> PDF转图片 <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-0d2be8ee data-v-f90b1660><a class="vp-link no-icon link" href="https://www.easyapi.top/" target="_blank" rel="noreferrer" data-v-f90b1660 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-f90b1660 data-v-72b81a46><img src="/icons/easy-api.svg" alt="" style="" data-v-72b81a46></span> Easy API <!----><!--]--><span class="vpi-external-link icon" data-v-3ce037c9></span></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/article/20jmp37t/" tabindex="0" data-v-3678d5a9 data-v-a950b8e7 data-v-3ce037c9><!--[--><span class="vp-icon-img" aria-hidden data-v-a950b8e7 data-v-72b81a46><img src="/icons/blog.svg" alt="" style="" data-v-72b81a46></span><span data-v-a950b8e7>关于我</span><!----><!--]--><!----></a><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-1ccbf436 data-v-018b14a6><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-018b14a6 data-v-248deb1b data-v-2892a536><span class="check" data-v-2892a536><span class="icon" data-v-2892a536><!--[--><span class="vpi-sun sun" data-v-248deb1b></span><span class="vpi-moon moon" data-v-248deb1b></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-1ccbf436 data-v-6e32fb9d data-v-de9c0d99><!--[--><a class="vp-social-link no-icon" href="https://github.com/ziqingchuan" aria-label="github" target="_blank" rel="noopener" data-v-de9c0d99 data-v-c7ebfad7><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-1ccbf436 data-v-a6578a43 data-v-9b8751cb><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-9b8751cb><span class="vpi-more-horizontal icon" data-v-9b8751cb></span></button><div class="menu" data-v-9b8751cb><div class="vp-menu" data-v-9b8751cb data-v-0d2be8ee><!----><!--[--><!--[--><!----><div class="group" data-v-a6578a43><div class="item appearance" data-v-a6578a43><p class="label" data-v-a6578a43>外观</p><div class="appearance-action" data-v-a6578a43><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-a6578a43 data-v-248deb1b data-v-2892a536><span class="check" data-v-2892a536><span class="icon" data-v-2892a536><!--[--><span class="vpi-sun sun" data-v-248deb1b></span><span class="vpi-moon moon" data-v-248deb1b></span><!--]--></span></span></button></div></div></div><div class="group" data-v-a6578a43><div class="item social-links" data-v-a6578a43><div class="vp-social-links social-links-list" data-v-a6578a43 data-v-de9c0d99><!--[--><a class="vp-social-link no-icon" href="https://github.com/ziqingchuan" aria-label="github" target="_blank" rel="noopener" data-v-de9c0d99 data-v-c7ebfad7><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-1ccbf436 data-v-839a5014><span class="container" data-v-839a5014><span class="top" data-v-839a5014></span><span class="middle" data-v-839a5014></span><span class="bottom" data-v-839a5014></span></span></button></div></div></div></div><div class="divider" data-v-1ccbf436><div class="divider-line" data-v-1ccbf436></div></div></div><!----></header><div class="vp-local-nav fixed reached-top is-blog" data-v-1817aa03 data-v-febfa1b2><button class="hidden menu" disabled aria-expanded="false" aria-controls="SidebarNav" data-v-febfa1b2><span class="vpi-align-left menu-icon" data-v-febfa1b2></span><span class="menu-text" data-v-febfa1b2>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-febfa1b2 data-v-22a174f4><button data-v-22a174f4>返回顶部</button><!----></div></div><!----><!--[--><div id="VPContent" vp-content class="vp-content" data-v-1817aa03 data-v-0ad81dc2><div class="vp-doc-container is-blog" data-v-0ad81dc2 data-v-5327a1c1><!--[--><!--]--><div class="container" data-v-5327a1c1><!----><div class="content" data-v-5327a1c1><div class="content-container" data-v-5327a1c1><!--[--><!--]--><main class="main" data-v-5327a1c1><nav class="vp-breadcrumb" data-v-5327a1c1 data-v-5bb0852e><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-5bb0852e><!--[--><li property="itemListElement" typeof="ListItem" data-v-5bb0852e><a class="vp-link no-icon link breadcrumb" href="/" property="item" typeof="WebPage" data-v-5bb0852e data-v-3ce037c9><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-5bb0852e></span><meta property="name" content="首页" data-v-5bb0852e><meta property="position" content="1" data-v-5bb0852e></li><li property="itemListElement" typeof="ListItem" data-v-5bb0852e><a class="vp-link no-icon link breadcrumb" href="/blog/" property="item" typeof="WebPage" data-v-5bb0852e data-v-3ce037c9><!--[-->博客<!--]--><!----></a><span class="vpi-chevron-right" data-v-5bb0852e></span><meta property="name" content="博客" data-v-5bb0852e><meta property="position" content="2" data-v-5bb0852e></li><li property="itemListElement" typeof="ListItem" data-v-5bb0852e><a class="vp-link no-icon link breadcrumb" href="/blog/categories/?id=0a40e3" property="item" typeof="WebPage" data-v-5bb0852e data-v-3ce037c9><!--[-->AI<!--]--><!----></a><span class="vpi-chevron-right" data-v-5bb0852e></span><meta property="name" content="AI" data-v-5bb0852e><meta property="position" content="3" data-v-5bb0852e></li><li property="itemListElement" typeof="ListItem" data-v-5bb0852e><a class="vp-link no-icon link breadcrumb current" href="/article/kw8yy12a/" property="item" typeof="WebPage" data-v-5bb0852e data-v-3ce037c9><!--[-->模型训练的梳理<!--]--><!----></a><!----><meta property="name" content="模型训练的梳理" data-v-5bb0852e><meta property="position" content="4" data-v-5bb0852e></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-9e9c015e>模型训练的梳理 <!----></h1><div class="vp-doc-meta" data-v-9e9c015e><!--[--><!--]--><p class="reading-time" data-v-9e9c015e><span class="vpi-books icon" data-v-9e9c015e></span><span data-v-9e9c015e>约 4418 字</span><span data-v-9e9c015e>大约 15 分钟</span></p><p data-v-9e9c015e><span class="vpi-tag icon" data-v-9e9c015e></span><!--[--><a class="vp-link no-icon link tag vp-tag-vkmt" href="/blog/tags/?tag=机器学习" data-v-9e9c015e data-v-3ce037c9><!--[-->机器学习<!--]--><!----></a><a class="vp-link no-icon link tag vp-tag-zj82" href="/blog/tags/?tag=模型训练" data-v-9e9c015e data-v-3ce037c9><!--[-->模型训练<!--]--><!----></a><a class="vp-link no-icon link tag vp-tag-s82c" href="/blog/tags/?tag=AI" data-v-9e9c015e data-v-3ce037c9><!--[-->AI<!--]--><!----></a><!--]--></p><!--[--><!--]--><p class="create-time" data-v-9e9c015e><span class="vpi-clock icon" data-v-9e9c015e></span><span data-v-9e9c015e>2025-07-11</span></p></div><!--]--><!--[--><!--]--><div class="_article_kw8yy12a_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-5327a1c1><!--[--><!--]--><div data-v-5327a1c1><h2 id="一、模型训练的完整过程" tabindex="-1"><a class="header-anchor" href="#一、模型训练的完整过程"><span>一、模型训练的完整过程</span></a></h2><p><mark class="note">机器学习模型的训练通常遵循固定流程，每个环节的质量都会直接影响最终模型的性能</mark>。</p><p>以下是训练的核心步骤：</p><h3 id="_1-数据准备与预处理" tabindex="-1"><a class="header-anchor" href="#_1-数据准备与预处理"><span>1. <mark>数据准备与预处理</mark></span></a></h3><ul><li><strong>数据收集</strong>：获取与任务相关的原始数据（如文本、图像、数值等），需保证数据的相关性和代表性。</li><li><strong>数据清洗</strong>：处理缺失值（填充、删除）、异常值（修正、剔除）、重复值（去重），避免噪声影响模型。</li><li><strong>特征工程</strong>： <ul><li>特征选择：筛选与目标相关的特征（如使用方差分析、互信息），减少冗余。</li><li>特征转换：标准化（如Z-score）、归一化（如Min-Max）、离散化（如将连续值分箱），使模型更易学习。</li><li>特征构建：通过组合或转换现有特征生成新特征（如多项式特征、文本的词向量）。</li></ul></li><li><strong>数据划分</strong>：将数据集分为训练集（70%-80%，用于模型学习）、验证集（10%-15%，用于调优超参数）、测试集（10%-15%，用于评估最终性能）。</li></ul><h3 id="_2-模型选择与初始化" tabindex="-1"><a class="header-anchor" href="#_2-模型选择与初始化"><span>2. <mark>模型选择与初始化</mark></span></a></h3><ul><li><strong>模型选择</strong>：根据任务类型（分类、回归、聚类等）和数据特点选择合适模型。例如： <ul><li><span class="vp-badge tip" style="" data-v-bf66b28b><!--[-->线性关系数据<!--]--></span>: 线性回归/逻辑回归；</li><li><span class="vp-badge warning" style="" data-v-bf66b28b><!--[-->非线性复杂关系<!--]--></span>: 决策树、神经网络；</li><li><span class="vp-badge danger" style="" data-v-bf66b28b><!--[-->高维稀疏数据<!--]--></span>: 支持向量机（SVM）、随机森林。</li></ul></li><li><strong>参数初始化</strong>：为模型的可学习参数（如权重、偏置）赋予初始值。常见策略包括： <ul><li><span class="vp-badge tip" style="" data-v-bf66b28b><!--[-->随机初始化<!--]--></span>：如正态分布、均匀分布（适用于神经网络）；</li><li><span class="vp-badge warning" style="" data-v-bf66b28b><!--[-->常数初始化<!--]--></span>：如全零初始化（需避免对称权重问题）；</li><li><span class="vp-badge danger" style="" data-v-bf66b28b><!--[-->预训练初始化<!--]--></span>：使用预训练模型的参数（如迁移学习中的BERT、ResNet）。</li></ul></li></ul><h3 id="_3-训练循环-核心过程" tabindex="-1"><a class="header-anchor" href="#_3-训练循环-核心过程"><span>3. <mark>训练循环（核心过程）</mark></span></a></h3><p>模型训练通过迭代优化参数，使预测结果逐渐接近真实标签，核心流程如下：</p><ol><li><strong>前向传播</strong>：将训练数据输入模型，计算预测值（如神经网络的输出、决策树的分类结果）。</li><li><strong>计算损失</strong>：通过损失函数对比预测值与真实标签，得到损失值（衡量预测误差的指标）。</li><li><strong>反向传播</strong>：基于损失值，使用链式法则计算参数的梯度（反映参数对损失的影响程度）。</li><li><strong>参数更新</strong>：通过优化器根据梯度调整模型参数，降低损失（如随机梯度下降法）。</li><li><strong>迭代终止</strong>：当达到最大迭代次数、损失收敛（变化小于阈值）或验证集性能下降时，停止训练。</li></ol><h3 id="_4-模型评估与调优" tabindex="-1"><a class="header-anchor" href="#_4-模型评估与调优"><span>4. <mark>模型评估与调优</mark></span></a></h3><ul><li><strong>评估指标</strong>：根据任务类型选择指标（如分类任务用准确率、F1分数；回归任务用MSE、R²）。</li><li><strong>调优方向</strong>：若模型欠拟合（训练/验证误差均高），需增加模型复杂度；若过拟合（训练误差低但验证误差高），需加入正则化或简化模型。</li><li><strong>模型保存</strong>：保存训练好的模型参数（如<code>.pth</code>、<code>.h5</code>文件），用于后续预测。</li></ul><h2 id="二、常见超参数及调优策略" tabindex="-1"><a class="header-anchor" href="#二、常见超参数及调优策略"><span>二、常见超参数及调优策略</span></a></h2><p><mark class="note">超参数是训练前手动设置的参数（非模型学习所得），直接影响模型性能</mark>。</p><p>以下是不同模型的核心超参数及调优方法：</p><h3 id="_1-通用超参数" tabindex="-1"><a class="header-anchor" href="#_1-通用超参数"><span>1. 通用超参数</span></a></h3><table><thead><tr><th>超参数</th><th>作用</th><th>常见范围</th><th>调优策略</th></tr></thead><tbody><tr><td>学习率（Learning Rate）</td><td>控制参数更新幅度</td><td>1e-5 ~ 1e-1</td><td>初期用较大值快速收敛，后期减小（如学习率衰减）</td></tr><tr><td>迭代次数（Epoch）</td><td>训练数据的遍历次数</td><td>10 ~ 1000</td><td>基于验证集性能，避免过拟合</td></tr><tr><td>批次大小（Batch Size）</td><td>每次迭代输入的样本数</td><td>16 ~ 256</td><td>小批次收敛慢但泛化好，大批量需匹配显存</td></tr></tbody></table><h3 id="_2-模型专属超参数" tabindex="-1"><a class="header-anchor" href="#_2-模型专属超参数"><span>2. 模型专属超参数</span></a></h3><ul><li><strong>决策树</strong>： <ul><li>最大深度（<code>max_depth</code>）：限制树的复杂度，防止过拟合（范围：3~30）。</li><li>叶子节点最小样本数（<code>min_samples_leaf</code>）：避免生成过小叶子（范围：1~10）。</li></ul></li><li><strong>随机森林</strong>： <ul><li>树的数量（<code>n_estimators</code>）：增加树数量可提升性能，但计算成本增加（范围：100~1000）。</li><li>特征采样比例（<code>max_features</code>）：控制每棵树使用的特征数（分类用平方根比例，回归用一半比例）。</li></ul></li><li><strong>支持向量机（SVM）</strong>： <ul><li>正则化参数（<code>C</code>）：平衡分类间隔与错误率（小C代表强正则化，范围：0.1~100）。</li><li>核函数参数（<code>gamma</code>）：控制核函数的影响范围（线性核无需设置，RBF核范围：1e-3~10）。</li></ul></li><li><strong>神经网络</strong>： <ul><li>隐藏层数量/神经元数：增加层数可提升拟合能力（如2-5层，每层16-512个神经元）。</li><li>dropout率：随机丢弃神经元比例（防止过拟合，范围：0.2~0.5）。</li></ul></li></ul><h3 id="_3-超参数调优策略" tabindex="-1"><a class="header-anchor" href="#_3-超参数调优策略"><span>3. 超参数调优策略</span></a></h3><ul><li><strong>网格搜索（Grid Search）</strong>：穷举预设参数组合（如学习率取[0.01, 0.1]，批次大小取[32, 64]），适合参数范围小的场景。</li><li><strong>随机搜索（Random Search）</strong>：在参数范围内随机采样组合，效率高于网格搜索，适合大范围参数。</li><li><strong>贝叶斯优化</strong>：基于历史参数性能，概率性选择下次参数，适合高维参数空间（如Optuna工具）。</li><li><strong>经验调优</strong>：先粗调范围（如学习率1e-5~1e-1），再聚焦最优区间微调。</li></ul><h2 id="三、常用优化器-optimizers" tabindex="-1"><a class="header-anchor" href="#三、常用优化器-optimizers"><span>三、常用优化器（Optimizers）</span></a></h2><p><mark class="note">优化器是用于更新模型参数的算法，核心目标是快速找到损失函数的最小值</mark>。</p><p>以下是主流优化器的特点及适用场景：</p><h3 id="_1-梯度下降类优化器" tabindex="-1"><a class="header-anchor" href="#_1-梯度下降类优化器"><span>1. <mark>梯度下降类优化器</mark></span></a></h3><ul><li><p><strong><span class="vp-badge tip" style="" data-v-bf66b28b><!--[-->随机梯度下降（SGD）<!--]--></span></strong>：</p><ul><li>参数更新方式：每次用单个样本的梯度调整参数</li><li>特点：每次用单个样本更新，收敛过程波动大但计算速度快。</li><li>适用场景：数据量大、简单模型（如线性回归）。</li><li>改进：加入动量（Momentum），模拟物理惯性，加速收敛并抑制震荡</li><li>动量更新逻辑：保留上一次的更新方向，结合当前梯度调整参数（动量系数通常取0.9）</li></ul></li><li><p><strong><span class="vp-badge warning" style="" data-v-bf66b28b><!--[-->批量梯度下降（BGD）<!--]--></span></strong>：</p><ul><li>特点：用全部样本计算梯度后更新参数，收敛稳定但计算成本高，适用于小数据集。</li></ul></li><li><p><strong><span class="vp-badge danger" style="" data-v-bf66b28b><!--[-->小批量梯度下降（Mini-batch GD）<!--]--></span></strong>：</p><ul><li>特点：平衡SGD和BGD，每次用一批样本（如32/64个）计算梯度并更新，是目前最常用的基础优化器。</li></ul></li></ul><h3 id="_2-自适应学习率优化器" tabindex="-1"><a class="header-anchor" href="#_2-自适应学习率优化器"><span>2. <mark>自适应学习率优化器</mark></span></a></h3><ul><li><p><strong><span class="vp-badge tip" style="" data-v-bf66b28b><!--[-->Adam（Adaptive Moment Estimation）<!--]--></span></strong>：</p><ul><li>核心逻辑：结合动量机制和自适应学习率，同时跟踪梯度的一阶矩（均值）和二阶矩（方差）</li><li>特点：收敛快且稳定，适用场景广泛（如神经网络、深度学习）。</li></ul></li><li><p><strong><span class="vp-badge warning" style="" data-v-bf66b28b><!--[-->RMSprop<!--]--></span></strong>：</p><ul><li>特点：仅通过梯度的二阶矩自适应调整学习率，适合处理非平稳目标（如递归神经网络RNN）。</li></ul></li><li><p><strong><span class="vp-badge danger" style="" data-v-bf66b28b><!--[-->Adagrad<!--]--></span></strong>：</p><ul><li>特点：学习率随参数更新次数增加而自动减小，适合稀疏数据（如自然语言处理），但可能过早停止更新。</li></ul></li></ul><h3 id="_3-优化器选择建议" tabindex="-1"><a class="header-anchor" href="#_3-优化器选择建议"><span>3. 优化器选择建议</span></a></h3><ul><li>新手首选<strong>Adam</strong>，兼顾效率与稳定性；</li><li>若模型收敛慢，尝试<strong>SGD+Momentum</strong>（需精细调整学习率）；</li><li>稀疏数据场景（如文本）可尝试<strong>Adagrad</strong>或<strong>RMSprop</strong>。</li></ul><h2 id="四、常用损失函数-loss-functions" tabindex="-1"><a class="header-anchor" href="#四、常用损失函数-loss-functions"><span>四、常用损失函数（Loss Functions）</span></a></h2><p><mark class="note">损失函数（Loss Function）量化模型预测与真实标签的差异，是参数更新的“指挥棒”</mark>。不同任务需匹配不同损失函数：</p><h3 id="_1-分类任务损失函数" tabindex="-1"><a class="header-anchor" href="#_1-分类任务损失函数"><span>1. 分类任务损失函数</span></a></h3><ul><li><p><strong>交叉熵损失（Cross-Entropy Loss）</strong>：</p><ul><li>二分类：通过预测概率与真实标签的对数差异计算损失</li><li>多分类：对每个类别的预测概率与真实标签的对数差异求和</li><li>特点：对错误预测的惩罚更显著，适用于逻辑回归、神经网络分类任务。</li></ul></li><li><p><strong>铰链损失（Hinge Loss）</strong>：</p><ul><li>核心逻辑：专注于分类边界，对正确分类且置信度高的样本惩罚小</li><li>特点：适用于支持向量机（SVM），强调最大化分类间隔。</li></ul></li></ul><h3 id="_2-回归任务损失函数" tabindex="-1"><a class="header-anchor" href="#_2-回归任务损失函数"><span>2. 回归任务损失函数</span></a></h3><ul><li><p><strong>均方误差（MSE）</strong>：</p><ul><li>计算方式：预测值与真实值之差的平方的平均值</li><li>特点：对异常值敏感（平方会放大误差），适用于误差呈正态分布的场景（如房价预测）。</li></ul></li><li><p><strong>平均绝对误差（MAE）</strong>：</p><ul><li>计算方式：预测值与真实值之差的绝对值的平均值</li><li>特点：对异常值更稳健，适用于误差分布不对称的场景（如风速预测）。</li></ul></li><li><p><strong>Huber损失</strong>：</p><ul><li>核心逻辑：误差较小时用平方误差（类似MSE），误差较大时用线性误差（类似MAE）</li><li>特点：结合MSE和MAE的优势，适用于含少量异常值的回归任务。</li></ul></li></ul><h3 id="_3-其他任务损失函数" tabindex="-1"><a class="header-anchor" href="#_3-其他任务损失函数"><span>3. 其他任务损失函数</span></a></h3><ul><li><strong>Dice损失</strong>：常用于图像分割，解决类别不平衡问题；</li><li><strong>对比损失</strong>：用于度量学习，拉近相似样本距离，拉远异类样本距离。</li></ul><h2 id="五、模型训练的调节机制" tabindex="-1"><a class="header-anchor" href="#五、模型训练的调节机制"><span>五、模型训练的调节机制</span></a></h2><p><mark class="note">训练过程中需通过调节机制避免过拟合、加速收敛</mark>，常见方法如下：</p><h3 id="_1-正则化-防止过拟合" tabindex="-1"><a class="header-anchor" href="#_1-正则化-防止过拟合"><span>1. 正则化（防止过拟合）</span></a></h3><ul><li><strong>L1正则化</strong>：在损失中加入参数绝对值之和，使部分参数为0，实现特征选择。</li><li><strong>L2正则化（权重衰减）</strong>：加入参数平方和，使参数值整体缩小，抑制过拟合。</li><li><strong>Dropout</strong>：训练时随机让部分神经元失效（如50%概率），强制模型学习冗余特征，适用于神经网络。</li><li><strong>早停机制（Early Stopping）</strong>：当验证集损失连续多轮上升时，停止训练，避免过拟合。</li></ul><h3 id="_2-学习率调度-learning-rate-scheduling" tabindex="-1"><a class="header-anchor" href="#_2-学习率调度-learning-rate-scheduling"><span>2. 学习率调度（Learning Rate Scheduling）</span></a></h3><ul><li><strong>分段衰减（Step Decay）</strong>：每训练一定轮数，学习率乘以衰减因子（如乘以0.1）。</li><li><strong>指数衰减</strong>：学习率随迭代次数按指数规律减小，适合快速收敛场景。</li><li><strong>余弦退火</strong>：学习率随迭代次数按余弦曲线变化，先降后升，帮助跳出局部最优。</li></ul><h3 id="_3-数据增强-data-augmentation" tabindex="-1"><a class="header-anchor" href="#_3-数据增强-data-augmentation"><span>3. 数据增强（Data Augmentation）</span></a></h3><p>通过对训练数据进行随机变换（如图像的旋转、裁剪，文本的同义词替换），增加数据多样性，抑制过拟合。适用于数据量小的场景（如深度学习图像任务）。</p><h3 id="_4-批归一化-batch-normalization" tabindex="-1"><a class="header-anchor" href="#_4-批归一化-batch-normalization"><span>4. 批归一化（Batch Normalization）</span></a></h3><p>对每批数据进行标准化（调整为均值0、方差1），稳定网络训练时的输入分布，加速收敛并允许更高学习率。广泛用于卷积神经网络（CNN）。</p><h2 id="六、模型评估指标" tabindex="-1"><a class="header-anchor" href="#六、模型评估指标"><span>六、模型评估指标</span></a></h2><p><mark class="note">模型评估是机器学习流程中至关重要的环节，用于衡量模型的性能表现，指导模型优化方向</mark>。</p><p>不同类型的任务（分类、回归、聚类等）有不同的评估指标，以下是详细介绍：</p><h3 id="分类任务评估指标" tabindex="-1"><a class="header-anchor" href="#分类任务评估指标"><span>分类任务评估指标</span></a></h3><p>分类任务的目标是将样本划分到预定义的类别中，评估指标主要围绕预测类别与真实类别的匹配程度展开。</p><ol><li><p><strong>混淆矩阵（Confusion Matrix）</strong></p><p>是分类任务的基础评估工具，通过四个核心指标描述模型表现：</p></li></ol><ul><li><strong>真正例（True Positive, TP）</strong>：实际为正类，模型预测为正类。</li><li><strong>假正例（False Positive, FP）</strong>：实际为负类，模型预测为正类（误判）。</li><li><strong>真负例（True Negative, TN）</strong>：实际为负类，模型预测为负类。</li><li><strong>假负例（False Negative, FN）</strong>：实际为正类，模型预测为负类（漏判）。</li></ul><ol start="2"><li><strong>准确率（Accuracy）</strong></li></ol><ul><li>定义：所有预测正确的样本占总样本的比例。</li><li>适用场景：适用于样本类别分布均衡的情况，不适用于不平衡数据集（如疾病检测中，少数正例的漏判影响更大）。</li></ul><ol start="3"><li><strong>精确率（Precision）</strong></li></ol><ul><li>定义：预测为正类的样本中，实际为正类的比例（关注“预测为正的可靠性”）。</li><li>适用场景：注重“减少误判”的场景，如垃圾邮件识别（避免将正常邮件误判为垃圾邮件）。</li></ul><ol start="4"><li><strong>召回率（Recall/Sensitivity/True Positive Rate, TPR）</strong></li></ol><ul><li>定义：实际为正类的样本中，被模型正确预测为正类的比例（关注“正例的覆盖能力”）。</li><li>适用场景：注重“减少漏判”的场景，如癌症检测（尽可能找出所有患者，允许少量误判）。</li></ul><ol start="5"><li><strong>F1分数（F1-Score）</strong></li></ol><ul><li>定义：精确率和召回率的调和平均数，综合两者的表现，避免单一指标的片面性。</li><li>适用场景：适用于类别不平衡或需要平衡精确率和召回率的场景（如文本分类）。</li></ul><ol start="6"><li><strong>ROC曲线与AUC（Area Under ROC Curve）</strong></li></ol><ul><li><strong>ROC曲线</strong>：以假正例率（FPR）为横轴，真正例率（TPR，即召回率）为纵轴，描述不同阈值下模型的区分能力。</li><li><strong>AUC</strong>：ROC曲线下的面积，取值范围为[0,1]。AUC越接近1，模型区分正负类的能力越强；AUC=0.5时，模型性能与随机猜测相当。</li><li>适用场景：尤其适用于不平衡数据集，对阈值不敏感，常用于二分类模型评估（如信用风险评估）。</li></ul><ol start="7"><li><strong>宏平均（Macro-average）与微平均（Micro-average）</strong></li></ol><ul><li>用于多分类任务，综合多个类别的评估指标： <ul><li><strong>宏平均</strong>：先计算每个类别的指标（如精确率），再取平均值，平等对待所有类别（适用于类别不平衡且关注小类别）。</li><li><strong>微平均</strong>：将所有类别的TP、FP、TN、FN汇总后计算指标，受样本量多的类别影响更大（适用于类别分布较均衡）。</li></ul></li></ul><h3 id="回归任务评估指标" tabindex="-1"><a class="header-anchor" href="#回归任务评估指标"><span>回归任务评估指标</span></a></h3><p>回归任务的目标是预测连续数值，评估指标主要衡量预测值与真实值的差异程度。</p><ol><li><strong>均方误差（Mean Squared Error, MSE）</strong></li></ol><ul><li>定义：预测值与真实值之差的平方的平均值。</li><li>特点：对异常值敏感（平方会放大误差），单位是目标值单位的平方，常用于模型训练的损失函数。</li></ul><ol start="2"><li><strong>均方根误差（Root Mean Squared Error, RMSE）</strong></li></ol><ul><li>定义：MSE的平方根，将误差转换为与目标值相同的单位。</li><li>特点：同样对异常值敏感，更直观反映误差大小（如预测房价时，RMSE单位为“元”）。</li></ul><ol start="3"><li><strong>平均绝对误差（Mean Absolute Error, MAE）</strong></li></ol><ul><li>定义：预测值与真实值之差的绝对值的平均值。</li><li>特点：对异常值不敏感，适用于数据中存在较多极端值的场景（如收入预测）。</li></ul><ol start="4"><li><strong>决定系数（Coefficient of Determination, R²）</strong></li></ol><ul><li>定义：衡量模型对数据变异的解释能力，取值范围为(-∞, 1]。</li><li>特点：R²越接近1，模型拟合效果越好；R²=0表示模型效果等同于均值预测；R²&lt;0表示模型效果差于均值预测。</li></ul><h3 id="聚类任务评估指标" tabindex="-1"><a class="header-anchor" href="#聚类任务评估指标"><span>聚类任务评估指标</span></a></h3><p>聚类任务无真实标签时，评估目标是衡量 “簇内相似度高、簇间差异大” 的程度。以下是几种常用的无监督聚类评估指标，从不同角度量化聚类结果的质量：</p><ol><li><strong>轮廓系数</strong>（Silhouette Coefficient）</li></ol><ul><li>核心思想：同时衡量样本与自身簇内其他样本的相似度（簇内紧密度），以及与最近邻簇中样本的相似度（簇间分离度），综合两者评估聚类合理性。</li><li>取值范围：([-1, 1])。 <ul><li>接近1：样本聚类合理，簇内紧密且簇间分离好。</li><li>接近0：样本处于两个簇的边界，聚类模糊。</li><li>接近-1：样本可能被分到错误的簇，聚类效果差。</li></ul></li><li>优点：无需真实标签，直观反映聚类的紧密度和分离度。</li><li>缺点：对噪声和离群点敏感，在簇形状不规则（如非凸簇）时表现不佳。</li></ul><ol start="2"><li><strong>Calinski-Harabasz指数</strong>（CH指数）</li></ol><ul><li>核心思想：通过簇间离散度与簇内离散度的比值评估聚类质量，比值越大说明聚类越好。</li><li>取值特点：值越大，说明簇间差异越大、簇内越集中，聚类效果越好。</li><li>优点：计算效率高，对凸形簇（如球形簇）效果较好。</li><li>缺点：对非凸簇或大小差异较大的簇不敏感，可能偏向于簇数量较多的聚类结果。</li></ul><ol start="3"><li><strong>Davies-Bouldin指数</strong>（DB指数）</li></ol><ul><li>核心思想：衡量每个簇与最相似的其他簇之间的“平均相似度”，相似度越低说明聚类越好。</li><li>取值特点：值越小，说明簇内越紧密且簇间越分离，聚类效果越好。</li><li>优点：对簇的数量不敏感，计算简单。</li><li>缺点：依赖于簇中心的定义，对非球形簇的适应性较差。</li></ul><ol start="4"><li><strong>Dunn指数</strong>（Dunn Index）</li></ol><ul><li>核心思想：通过“最小簇间距离”与“最大簇内直径”的比值评估聚类质量，比值越大说明聚类越好。</li><li>取值特点：值越大，说明簇间距离越大、簇内样本越集中，聚类效果越好。</li><li>优点：对紧凑且分离良好的簇敏感，能反映簇的边界清晰度。</li><li>缺点：计算复杂度高（需遍历所有样本对），对高维数据和噪声敏感。</li></ul></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-5327a1c1 data-v-0bb0f269><!--[--><!--]--><!----><div class="contributors" aria-label="Contributors" data-v-0bb0f269><span class="contributors-label" data-v-0bb0f269>贡献者: </span><span class="contributors-info" data-v-0bb0f269><!--[--><!--[--><span class="contributor" data-v-0bb0f269>221250108</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-0bb0f269><div class="pager" data-v-0bb0f269><a class="vp-link no-icon link pager-link prev" href="/article/eb2rw5pv/" data-v-0bb0f269 data-v-3ce037c9><!--[--><span class="desc" data-v-0bb0f269>上一页</span><span class="title" data-v-0bb0f269>强制缓存与协商缓存</span><!--]--><!----></a></div><div class="pager" data-v-0bb0f269><a class="vp-link no-icon link pager-link next" href="/article/yp69l34o/" data-v-0bb0f269 data-v-3ce037c9><!--[--><span class="desc" data-v-0bb0f269>下一页</span><span class="title" data-v-0bb0f269>机器学习方法</span><!--]--><!----></a></div></nav></footer><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;" data-v-5327a1c1><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-1817aa03 data-v-4e018625><span class="percent" data-allow-mismatch data-v-4e018625>0%</span><span class="show icon vpi-back-to-top" data-v-4e018625></span><svg aria-hidden="true" data-v-4e018625><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-4e018625></circle></svg></button><footer class="vp-footer" vp-footer data-v-1817aa03 data-v-1b71e06e><!--[--><div class="container" data-v-1b71e06e><p class="message" data-v-1b71e06e>由 <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> 提供技术支持，主题来自 <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-1b71e06e>© 2025  try-catch.life</p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-CYGu30PL.js" defer></script></body></html>