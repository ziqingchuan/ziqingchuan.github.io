import{_ as o,c as s,a,b as l,d as i,e as r,r as e,o as p}from"./app-B5A89ofV.js";const u={};function d(g,t){const n=e("Badge");return p(),s("div",null,[t[22]||(t[22]=a('<h2 id="一、模型训练的完整过程" tabindex="-1"><a class="header-anchor" href="#一、模型训练的完整过程"><span>一、模型训练的完整过程</span></a></h2><p><mark class="note">机器学习模型的训练通常遵循固定流程，每个环节的质量都会直接影响最终模型的性能</mark>。</p><p>以下是训练的核心步骤：</p><h3 id="_1-数据准备与预处理" tabindex="-1"><a class="header-anchor" href="#_1-数据准备与预处理"><span>1. <mark>数据准备与预处理</mark></span></a></h3><ul><li><strong>数据收集</strong>：获取与任务相关的原始数据（如文本、图像、数值等），需保证数据的相关性和代表性。</li><li><strong>数据清洗</strong>：处理缺失值（填充、删除）、异常值（修正、剔除）、重复值（去重），避免噪声影响模型。</li><li><strong>特征工程</strong>： <ul><li>特征选择：筛选与目标相关的特征（如使用方差分析、互信息），减少冗余。</li><li>特征转换：标准化（如Z-score）、归一化（如Min-Max）、离散化（如将连续值分箱），使模型更易学习。</li><li>特征构建：通过组合或转换现有特征生成新特征（如多项式特征、文本的词向量）。</li></ul></li><li><strong>数据划分</strong>：将数据集分为训练集（70%-80%，用于模型学习）、验证集（10%-15%，用于调优超参数）、测试集（10%-15%，用于评估最终性能）。</li></ul><h3 id="_2-模型选择与初始化" tabindex="-1"><a class="header-anchor" href="#_2-模型选择与初始化"><span>2. <mark>模型选择与初始化</mark></span></a></h3>',6)),l("ul",null,[l("li",null,[t[3]||(t[3]=l("strong",null,"模型选择",-1)),t[4]||(t[4]=i("：根据任务类型（分类、回归、聚类等）和数据特点选择合适模型。例如： ",-1)),l("ul",null,[l("li",null,[r(n,{text:"线性关系数据",type:"tip"}),t[0]||(t[0]=i(": 线性回归/逻辑回归；",-1))]),l("li",null,[r(n,{text:"非线性复杂关系",type:"warning"}),t[1]||(t[1]=i(": 决策树、神经网络；",-1))]),l("li",null,[r(n,{text:"高维稀疏数据",type:"danger"}),t[2]||(t[2]=i(": 支持向量机（SVM）、随机森林。",-1))])])]),l("li",null,[t[8]||(t[8]=l("strong",null,"参数初始化",-1)),t[9]||(t[9]=i("：为模型的可学习参数（如权重、偏置）赋予初始值。常见策略包括： ",-1)),l("ul",null,[l("li",null,[r(n,{text:"随机初始化",type:"tip"}),t[5]||(t[5]=i("：如正态分布、均匀分布（适用于神经网络）；",-1))]),l("li",null,[r(n,{text:"常数初始化",type:"warning"}),t[6]||(t[6]=i("：如全零初始化（需避免对称权重问题）；",-1))]),l("li",null,[r(n,{text:"预训练初始化",type:"danger"}),t[7]||(t[7]=i("：使用预训练模型的参数（如迁移学习中的BERT、ResNet）。",-1))])])])]),t[23]||(t[23]=a('<h3 id="_3-训练循环-核心过程" tabindex="-1"><a class="header-anchor" href="#_3-训练循环-核心过程"><span>3. <mark>训练循环（核心过程）</mark></span></a></h3><p>模型训练通过迭代优化参数，使预测结果逐渐接近真实标签，核心流程如下：</p><ol><li><strong>前向传播</strong>：将训练数据输入模型，计算预测值（如神经网络的输出、决策树的分类结果）。</li><li><strong>计算损失</strong>：通过损失函数对比预测值与真实标签，得到损失值（衡量预测误差的指标）。</li><li><strong>反向传播</strong>：基于损失值，使用链式法则计算参数的梯度（反映参数对损失的影响程度）。</li><li><strong>参数更新</strong>：通过优化器根据梯度调整模型参数，降低损失（如随机梯度下降法）。</li><li><strong>迭代终止</strong>：当达到最大迭代次数、损失收敛（变化小于阈值）或验证集性能下降时，停止训练。</li></ol><h3 id="_4-模型评估与调优" tabindex="-1"><a class="header-anchor" href="#_4-模型评估与调优"><span>4. <mark>模型评估与调优</mark></span></a></h3><ul><li><strong>评估指标</strong>：根据任务类型选择指标（如分类任务用准确率、F1分数；回归任务用MSE、R²）。</li><li><strong>调优方向</strong>：若模型欠拟合（训练/验证误差均高），需增加模型复杂度；若过拟合（训练误差低但验证误差高），需加入正则化或简化模型。</li><li><strong>模型保存</strong>：保存训练好的模型参数（如<code>.pth</code>、<code>.h5</code>文件），用于后续预测。</li></ul><h2 id="二、常见超参数及调优策略" tabindex="-1"><a class="header-anchor" href="#二、常见超参数及调优策略"><span>二、常见超参数及调优策略</span></a></h2><p><mark class="note">超参数是训练前手动设置的参数（非模型学习所得），直接影响模型性能</mark>。</p><p>以下是不同模型的核心超参数及调优方法：</p><h3 id="_1-通用超参数" tabindex="-1"><a class="header-anchor" href="#_1-通用超参数"><span>1. 通用超参数</span></a></h3><table><thead><tr><th>超参数</th><th>作用</th><th>常见范围</th><th>调优策略</th></tr></thead><tbody><tr><td>学习率（Learning Rate）</td><td>控制参数更新幅度</td><td>1e-5 ~ 1e-1</td><td>初期用较大值快速收敛，后期减小（如学习率衰减）</td></tr><tr><td>迭代次数（Epoch）</td><td>训练数据的遍历次数</td><td>10 ~ 1000</td><td>基于验证集性能，避免过拟合</td></tr><tr><td>批次大小（Batch Size）</td><td>每次迭代输入的样本数</td><td>16 ~ 256</td><td>小批次收敛慢但泛化好，大批量需匹配显存</td></tr></tbody></table><h3 id="_2-模型专属超参数" tabindex="-1"><a class="header-anchor" href="#_2-模型专属超参数"><span>2. 模型专属超参数</span></a></h3><ul><li><strong>决策树</strong>： <ul><li>最大深度（<code>max_depth</code>）：限制树的复杂度，防止过拟合（范围：3~30）。</li><li>叶子节点最小样本数（<code>min_samples_leaf</code>）：避免生成过小叶子（范围：1~10）。</li></ul></li><li><strong>随机森林</strong>： <ul><li>树的数量（<code>n_estimators</code>）：增加树数量可提升性能，但计算成本增加（范围：100~1000）。</li><li>特征采样比例（<code>max_features</code>）：控制每棵树使用的特征数（分类用平方根比例，回归用一半比例）。</li></ul></li><li><strong>支持向量机（SVM）</strong>： <ul><li>正则化参数（<code>C</code>）：平衡分类间隔与错误率（小C代表强正则化，范围：0.1~100）。</li><li>核函数参数（<code>gamma</code>）：控制核函数的影响范围（线性核无需设置，RBF核范围：1e-3~10）。</li></ul></li><li><strong>神经网络</strong>： <ul><li>隐藏层数量/神经元数：增加层数可提升拟合能力（如2-5层，每层16-512个神经元）。</li><li>dropout率：随机丢弃神经元比例（防止过拟合，范围：0.2~0.5）。</li></ul></li></ul><h3 id="_3-超参数调优策略" tabindex="-1"><a class="header-anchor" href="#_3-超参数调优策略"><span>3. 超参数调优策略</span></a></h3><ul><li><strong>网格搜索（Grid Search）</strong>：穷举预设参数组合（如学习率取[0.01, 0.1]，批次大小取[32, 64]），适合参数范围小的场景。</li><li><strong>随机搜索（Random Search）</strong>：在参数范围内随机采样组合，效率高于网格搜索，适合大范围参数。</li><li><strong>贝叶斯优化</strong>：基于历史参数性能，概率性选择下次参数，适合高维参数空间（如Optuna工具）。</li><li><strong>经验调优</strong>：先粗调范围（如学习率1e-5~1e-1），再聚焦最优区间微调。</li></ul><h2 id="三、常用优化器-optimizers" tabindex="-1"><a class="header-anchor" href="#三、常用优化器-optimizers"><span>三、常用优化器（Optimizers）</span></a></h2><p><mark class="note">优化器是用于更新模型参数的算法，核心目标是快速找到损失函数的最小值</mark>。</p><p>以下是主流优化器的特点及适用场景：</p><h3 id="_1-梯度下降类优化器" tabindex="-1"><a class="header-anchor" href="#_1-梯度下降类优化器"><span>1. <mark>梯度下降类优化器</mark></span></a></h3>',18)),l("ul",null,[l("li",null,[l("p",null,[l("strong",null,[r(n,{text:"随机梯度下降（SGD）",type:"tip"})]),t[10]||(t[10]=i("：",-1))]),t[11]||(t[11]=l("ul",null,[l("li",null,"参数更新方式：每次用单个样本的梯度调整参数"),l("li",null,"特点：每次用单个样本更新，收敛过程波动大但计算速度快。"),l("li",null,"适用场景：数据量大、简单模型（如线性回归）。"),l("li",null,"改进：加入动量（Momentum），模拟物理惯性，加速收敛并抑制震荡"),l("li",null,"动量更新逻辑：保留上一次的更新方向，结合当前梯度调整参数（动量系数通常取0.9）")],-1))]),l("li",null,[l("p",null,[l("strong",null,[r(n,{text:"批量梯度下降（BGD）",type:"warning"})]),t[12]||(t[12]=i("：",-1))]),t[13]||(t[13]=l("ul",null,[l("li",null,"特点：用全部样本计算梯度后更新参数，收敛稳定但计算成本高，适用于小数据集。")],-1))]),l("li",null,[l("p",null,[l("strong",null,[r(n,{text:"小批量梯度下降（Mini-batch GD）",type:"danger"})]),t[14]||(t[14]=i("：",-1))]),t[15]||(t[15]=l("ul",null,[l("li",null,"特点：平衡SGD和BGD，每次用一批样本（如32/64个）计算梯度并更新，是目前最常用的基础优化器。")],-1))])]),t[24]||(t[24]=l("h3",{id:"_2-自适应学习率优化器",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#_2-自适应学习率优化器"},[l("span",null,[i("2. "),l("mark",null,"自适应学习率优化器")])])],-1)),l("ul",null,[l("li",null,[l("p",null,[l("strong",null,[r(n,{text:"Adam（Adaptive Moment Estimation）",type:"tip"})]),t[16]||(t[16]=i("：",-1))]),t[17]||(t[17]=l("ul",null,[l("li",null,"核心逻辑：结合动量机制和自适应学习率，同时跟踪梯度的一阶矩（均值）和二阶矩（方差）"),l("li",null,"特点：收敛快且稳定，适用场景广泛（如神经网络、深度学习）。")],-1))]),l("li",null,[l("p",null,[l("strong",null,[r(n,{text:"RMSprop",type:"warning"})]),t[18]||(t[18]=i("：",-1))]),t[19]||(t[19]=l("ul",null,[l("li",null,"特点：仅通过梯度的二阶矩自适应调整学习率，适合处理非平稳目标（如递归神经网络RNN）。")],-1))]),l("li",null,[l("p",null,[l("strong",null,[r(n,{text:"Adagrad",type:"danger"})]),t[20]||(t[20]=i("：",-1))]),t[21]||(t[21]=l("ul",null,[l("li",null,"特点：学习率随参数更新次数增加而自动减小，适合稀疏数据（如自然语言处理），但可能过早停止更新。")],-1))])]),t[25]||(t[25]=a('<h3 id="_3-优化器选择建议" tabindex="-1"><a class="header-anchor" href="#_3-优化器选择建议"><span>3. 优化器选择建议</span></a></h3><ul><li>新手首选<strong>Adam</strong>，兼顾效率与稳定性；</li><li>若模型收敛慢，尝试<strong>SGD+Momentum</strong>（需精细调整学习率）；</li><li>稀疏数据场景（如文本）可尝试<strong>Adagrad</strong>或<strong>RMSprop</strong>。</li></ul><h2 id="四、常用损失函数-loss-functions" tabindex="-1"><a class="header-anchor" href="#四、常用损失函数-loss-functions"><span>四、常用损失函数（Loss Functions）</span></a></h2><p><mark class="note">损失函数（Loss Function）量化模型预测与真实标签的差异，是参数更新的“指挥棒”</mark>。不同任务需匹配不同损失函数：</p><h3 id="_1-分类任务损失函数" tabindex="-1"><a class="header-anchor" href="#_1-分类任务损失函数"><span>1. 分类任务损失函数</span></a></h3><ul><li><p><strong>交叉熵损失（Cross-Entropy Loss）</strong>：</p><ul><li>二分类：通过预测概率与真实标签的对数差异计算损失</li><li>多分类：对每个类别的预测概率与真实标签的对数差异求和</li><li>特点：对错误预测的惩罚更显著，适用于逻辑回归、神经网络分类任务。</li></ul></li><li><p><strong>铰链损失（Hinge Loss）</strong>：</p><ul><li>核心逻辑：专注于分类边界，对正确分类且置信度高的样本惩罚小</li><li>特点：适用于支持向量机（SVM），强调最大化分类间隔。</li></ul></li></ul><h3 id="_2-回归任务损失函数" tabindex="-1"><a class="header-anchor" href="#_2-回归任务损失函数"><span>2. 回归任务损失函数</span></a></h3><ul><li><p><strong>均方误差（MSE）</strong>：</p><ul><li>计算方式：预测值与真实值之差的平方的平均值</li><li>特点：对异常值敏感（平方会放大误差），适用于误差呈正态分布的场景（如房价预测）。</li></ul></li><li><p><strong>平均绝对误差（MAE）</strong>：</p><ul><li>计算方式：预测值与真实值之差的绝对值的平均值</li><li>特点：对异常值更稳健，适用于误差分布不对称的场景（如风速预测）。</li></ul></li><li><p><strong>Huber损失</strong>：</p><ul><li>核心逻辑：误差较小时用平方误差（类似MSE），误差较大时用线性误差（类似MAE）</li><li>特点：结合MSE和MAE的优势，适用于含少量异常值的回归任务。</li></ul></li></ul><h3 id="_3-其他任务损失函数" tabindex="-1"><a class="header-anchor" href="#_3-其他任务损失函数"><span>3. 其他任务损失函数</span></a></h3><ul><li><strong>Dice损失</strong>：常用于图像分割，解决类别不平衡问题；</li><li><strong>对比损失</strong>：用于度量学习，拉近相似样本距离，拉远异类样本距离。</li></ul><h2 id="五、模型训练的调节机制" tabindex="-1"><a class="header-anchor" href="#五、模型训练的调节机制"><span>五、模型训练的调节机制</span></a></h2><p><mark class="note">训练过程中需通过调节机制避免过拟合、加速收敛</mark>，常见方法如下：</p><h3 id="_1-正则化-防止过拟合" tabindex="-1"><a class="header-anchor" href="#_1-正则化-防止过拟合"><span>1. 正则化（防止过拟合）</span></a></h3><ul><li><strong>L1正则化</strong>：在损失中加入参数绝对值之和，使部分参数为0，实现特征选择。</li><li><strong>L2正则化（权重衰减）</strong>：加入参数平方和，使参数值整体缩小，抑制过拟合。</li><li><strong>Dropout</strong>：训练时随机让部分神经元失效（如50%概率），强制模型学习冗余特征，适用于神经网络。</li><li><strong>早停机制（Early Stopping）</strong>：当验证集损失连续多轮上升时，停止训练，避免过拟合。</li></ul><h3 id="_2-学习率调度-learning-rate-scheduling" tabindex="-1"><a class="header-anchor" href="#_2-学习率调度-learning-rate-scheduling"><span>2. 学习率调度（Learning Rate Scheduling）</span></a></h3><ul><li><strong>分段衰减（Step Decay）</strong>：每训练一定轮数，学习率乘以衰减因子（如乘以0.1）。</li><li><strong>指数衰减</strong>：学习率随迭代次数按指数规律减小，适合快速收敛场景。</li><li><strong>余弦退火</strong>：学习率随迭代次数按余弦曲线变化，先降后升，帮助跳出局部最优。</li></ul><h3 id="_3-数据增强-data-augmentation" tabindex="-1"><a class="header-anchor" href="#_3-数据增强-data-augmentation"><span>3. 数据增强（Data Augmentation）</span></a></h3><p>通过对训练数据进行随机变换（如图像的旋转、裁剪，文本的同义词替换），增加数据多样性，抑制过拟合。适用于数据量小的场景（如深度学习图像任务）。</p><h3 id="_4-批归一化-batch-normalization" tabindex="-1"><a class="header-anchor" href="#_4-批归一化-batch-normalization"><span>4. 批归一化（Batch Normalization）</span></a></h3><p>对每批数据进行标准化（调整为均值0、方差1），稳定网络训练时的输入分布，加速收敛并允许更高学习率。广泛用于卷积神经网络（CNN）。</p><h2 id="六、模型评估指标" tabindex="-1"><a class="header-anchor" href="#六、模型评估指标"><span>六、模型评估指标</span></a></h2><p><mark class="note">模型评估是机器学习流程中至关重要的环节，用于衡量模型的性能表现，指导模型优化方向</mark>。</p><p>不同类型的任务（分类、回归、聚类等）有不同的评估指标，以下是详细介绍：</p><h3 id="分类任务评估指标" tabindex="-1"><a class="header-anchor" href="#分类任务评估指标"><span>分类任务评估指标</span></a></h3><p>分类任务的目标是将样本划分到预定义的类别中，评估指标主要围绕预测类别与真实类别的匹配程度展开。</p><ol><li><p><strong>混淆矩阵（Confusion Matrix）</strong></p><p>是分类任务的基础评估工具，通过四个核心指标描述模型表现：</p></li></ol><ul><li><strong>真正例（True Positive, TP）</strong>：实际为正类，模型预测为正类。</li><li><strong>假正例（False Positive, FP）</strong>：实际为负类，模型预测为正类（误判）。</li><li><strong>真负例（True Negative, TN）</strong>：实际为负类，模型预测为负类。</li><li><strong>假负例（False Negative, FN）</strong>：实际为正类，模型预测为负类（漏判）。</li></ul><ol start="2"><li><strong>准确率（Accuracy）</strong></li></ol><ul><li>定义：所有预测正确的样本占总样本的比例。</li><li>适用场景：适用于样本类别分布均衡的情况，不适用于不平衡数据集（如疾病检测中，少数正例的漏判影响更大）。</li></ul><ol start="3"><li><strong>精确率（Precision）</strong></li></ol><ul><li>定义：预测为正类的样本中，实际为正类的比例（关注“预测为正的可靠性”）。</li><li>适用场景：注重“减少误判”的场景，如垃圾邮件识别（避免将正常邮件误判为垃圾邮件）。</li></ul><ol start="4"><li><strong>召回率（Recall/Sensitivity/True Positive Rate, TPR）</strong></li></ol><ul><li>定义：实际为正类的样本中，被模型正确预测为正类的比例（关注“正例的覆盖能力”）。</li><li>适用场景：注重“减少漏判”的场景，如癌症检测（尽可能找出所有患者，允许少量误判）。</li></ul><ol start="5"><li><strong>F1分数（F1-Score）</strong></li></ol><ul><li>定义：精确率和召回率的调和平均数，综合两者的表现，避免单一指标的片面性。</li><li>适用场景：适用于类别不平衡或需要平衡精确率和召回率的场景（如文本分类）。</li></ul><ol start="6"><li><strong>ROC曲线与AUC（Area Under ROC Curve）</strong></li></ol><ul><li><strong>ROC曲线</strong>：以假正例率（FPR）为横轴，真正例率（TPR，即召回率）为纵轴，描述不同阈值下模型的区分能力。</li><li><strong>AUC</strong>：ROC曲线下的面积，取值范围为[0,1]。AUC越接近1，模型区分正负类的能力越强；AUC=0.5时，模型性能与随机猜测相当。</li><li>适用场景：尤其适用于不平衡数据集，对阈值不敏感，常用于二分类模型评估（如信用风险评估）。</li></ul><ol start="7"><li><strong>宏平均（Macro-average）与微平均（Micro-average）</strong></li></ol><ul><li>用于多分类任务，综合多个类别的评估指标： <ul><li><strong>宏平均</strong>：先计算每个类别的指标（如精确率），再取平均值，平等对待所有类别（适用于类别不平衡且关注小类别）。</li><li><strong>微平均</strong>：将所有类别的TP、FP、TN、FN汇总后计算指标，受样本量多的类别影响更大（适用于类别分布较均衡）。</li></ul></li></ul><h3 id="回归任务评估指标" tabindex="-1"><a class="header-anchor" href="#回归任务评估指标"><span>回归任务评估指标</span></a></h3><p>回归任务的目标是预测连续数值，评估指标主要衡量预测值与真实值的差异程度。</p><ol><li><strong>均方误差（Mean Squared Error, MSE）</strong></li></ol><ul><li>定义：预测值与真实值之差的平方的平均值。</li><li>特点：对异常值敏感（平方会放大误差），单位是目标值单位的平方，常用于模型训练的损失函数。</li></ul><ol start="2"><li><strong>均方根误差（Root Mean Squared Error, RMSE）</strong></li></ol><ul><li>定义：MSE的平方根，将误差转换为与目标值相同的单位。</li><li>特点：同样对异常值敏感，更直观反映误差大小（如预测房价时，RMSE单位为“元”）。</li></ul><ol start="3"><li><strong>平均绝对误差（Mean Absolute Error, MAE）</strong></li></ol><ul><li>定义：预测值与真实值之差的绝对值的平均值。</li><li>特点：对异常值不敏感，适用于数据中存在较多极端值的场景（如收入预测）。</li></ul><ol start="4"><li><strong>决定系数（Coefficient of Determination, R²）</strong></li></ol><ul><li>定义：衡量模型对数据变异的解释能力，取值范围为(-∞, 1]。</li><li>特点：R²越接近1，模型拟合效果越好；R²=0表示模型效果等同于均值预测；R²&lt;0表示模型效果差于均值预测。</li></ul><h3 id="聚类任务评估指标" tabindex="-1"><a class="header-anchor" href="#聚类任务评估指标"><span>聚类任务评估指标</span></a></h3><p>聚类任务无真实标签时，评估目标是衡量 “簇内相似度高、簇间差异大” 的程度。以下是几种常用的无监督聚类评估指标，从不同角度量化聚类结果的质量：</p><ol><li><strong>轮廓系数</strong>（Silhouette Coefficient）</li></ol><ul><li>核心思想：同时衡量样本与自身簇内其他样本的相似度（簇内紧密度），以及与最近邻簇中样本的相似度（簇间分离度），综合两者评估聚类合理性。</li><li>取值范围：([-1, 1])。 <ul><li>接近1：样本聚类合理，簇内紧密且簇间分离好。</li><li>接近0：样本处于两个簇的边界，聚类模糊。</li><li>接近-1：样本可能被分到错误的簇，聚类效果差。</li></ul></li><li>优点：无需真实标签，直观反映聚类的紧密度和分离度。</li><li>缺点：对噪声和离群点敏感，在簇形状不规则（如非凸簇）时表现不佳。</li></ul><ol start="2"><li><strong>Calinski-Harabasz指数</strong>（CH指数）</li></ol><ul><li>核心思想：通过簇间离散度与簇内离散度的比值评估聚类质量，比值越大说明聚类越好。</li><li>取值特点：值越大，说明簇间差异越大、簇内越集中，聚类效果越好。</li><li>优点：计算效率高，对凸形簇（如球形簇）效果较好。</li><li>缺点：对非凸簇或大小差异较大的簇不敏感，可能偏向于簇数量较多的聚类结果。</li></ul><ol start="3"><li><strong>Davies-Bouldin指数</strong>（DB指数）</li></ol><ul><li>核心思想：衡量每个簇与最相似的其他簇之间的“平均相似度”，相似度越低说明聚类越好。</li><li>取值特点：值越小，说明簇内越紧密且簇间越分离，聚类效果越好。</li><li>优点：对簇的数量不敏感，计算简单。</li><li>缺点：依赖于簇中心的定义，对非球形簇的适应性较差。</li></ul><ol start="4"><li><strong>Dunn指数</strong>（Dunn Index）</li></ol><ul><li>核心思想：通过“最小簇间距离”与“最大簇内直径”的比值评估聚类质量，比值越大说明聚类越好。</li><li>取值特点：值越大，说明簇间距离越大、簇内样本越集中，聚类效果越好。</li><li>优点：对紧凑且分离良好的簇敏感，能反映簇的边界清晰度。</li><li>缺点：计算复杂度高（需遍历所有样本对），对高维数据和噪声敏感。</li></ul>',59))])}const m=o(u,[["render",d]]),c=JSON.parse('{"path":"/article/kw8yy12a/","title":"模型训练的梳理","lang":"zh-CN","frontmatter":{"title":"模型训练的梳理","createTime":"2025/07/11 11:50:29","permalink":"/article/kw8yy12a/","tags":["机器学习","模型训练","AI"],"excerpt":"详细梳理训练模型的全流程的相关知识点。","description":"一、模型训练的完整过程 机器学习模型的训练通常遵循固定流程，每个环节的质量都会直接影响最终模型的性能。 以下是训练的核心步骤： 1. 数据准备与预处理 数据收集：获取与任务相关的原始数据（如文本、图像、数值等），需保证数据的相关性和代表性。 数据清洗：处理缺失值（填充、删除）、异常值（修正、剔除）、重复值（去重），避免噪声影响模型。 特征工程： 特征选...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"模型训练的梳理\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-07-12T11:41:17.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://try-catch.life/article/kw8yy12a/"}],["meta",{"property":"og:site_name","content":"码不停蹄"}],["meta",{"property":"og:title","content":"模型训练的梳理"}],["meta",{"property":"og:description","content":"一、模型训练的完整过程 机器学习模型的训练通常遵循固定流程，每个环节的质量都会直接影响最终模型的性能。 以下是训练的核心步骤： 1. 数据准备与预处理 数据收集：获取与任务相关的原始数据（如文本、图像、数值等），需保证数据的相关性和代表性。 数据清洗：处理缺失值（填充、删除）、异常值（修正、剔除）、重复值（去重），避免噪声影响模型。 特征工程： 特征选..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-07-12T11:41:17.000Z"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:tag","content":"模型训练"}],["meta",{"property":"article:tag","content":"机器学习"}],["meta",{"property":"article:modified_time","content":"2025-07-12T11:41:17.000Z"}]]},"readingTime":{"minutes":14.73,"words":4418},"git":{"createdTime":1752207501000,"updatedTime":1752320477000,"contributors":[{"name":"221250108","username":"221250108","email":"221250108@smail.nju.edu.cn","commits":2,"avatar":"https://avatars.githubusercontent.com/221250108?v=4","url":"https://github.com/221250108"}]},"autoDesc":true,"filePathRelative":"AI/模型训练的梳理.md","headers":[],"categoryList":[{"id":"0a40e3","sort":10005,"name":"AI"}]}');export{m as comp,c as data};
